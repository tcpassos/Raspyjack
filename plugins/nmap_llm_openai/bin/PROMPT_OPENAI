#!/usr/bin/env python3
import sys
import os
import json
from plugins.nmap_llm_openai.helpers import OpenAIHelper

CONFIG_PATH = os.path.join(os.path.dirname(__file__), '..', '..', 'plugins_conf.json')

def get_plugin_config():
    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            conf = json.load(f)
        return conf.get('nmap_llm_openai', {}).get('options', {})
    except Exception:
        return None

def main():
    if len(sys.argv) < 2:
        print("Usage: PROMPT_OPENAI <prompt>")
        print("The output will be saved to a file and the path set in the AI_OUTPUT_PATH environment variable.")
        sys.exit(1)
    prompt = sys.argv[1]
    config = get_plugin_config()
    if not config:
        print("[ERROR] Could not load plugin configuration.")
        sys.exit(1)
    api_key = config.get('api_key', '')
    language = config.get('language', 'en')
    model = config.get('model', 'gpt-5-nano')
    helper = OpenAIHelper(api_key, language, model)
    result = helper.prompt(prompt)
    # Prepare output path
    loot_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'loot', 'AI')
    os.makedirs(loot_dir, exist_ok=True)
    import datetime
    fname = f"ai_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    out_path = os.path.abspath(os.path.join(loot_dir, fname))
    with open(out_path, 'w', encoding='utf-8') as f:
        f.write(result)
    # Set environment variable
    os.environ['AI_OUTPUT_PATH'] = out_path
    print(result)

if __name__ == "__main__":
    main()
